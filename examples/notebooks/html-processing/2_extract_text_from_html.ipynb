{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing HTML Files\n",
    "\n",
    "We will be using **html2parquet transform**\n",
    "\n",
    "References\n",
    "- [html2parquet](https://github.com/IBM/data-prep-kit/tree/dev/transforms/language/html2parquet/python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Data\n",
    "\n",
    "We will process data that is downloaded using [1_crawl_site.ipynb](1_crawl_site.ipynb).\n",
    "\n",
    "We have a couple of crawled HTML files in  `input` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All config is defined here\n",
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleared  output directory\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_DIR, ignore_errors=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_DIR, exist_ok=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_DIR_HTML, exist_ok=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_DIR_MARKDOWN, exist_ok=True)\n",
    "\n",
    "print (\"✅ Cleared  output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: HTML2Parquet\n",
    "\n",
    "Process HTML documents and extract the text in markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:23:09 INFO - html2parquet parameters are : {'output_format': <html2parquet_output_format.MARKDOWN: 'markdown'>, 'favor_precision': <html2parquet_favor_precision.TRUE: 'True'>, 'favor_recall': <html2parquet_favor_recall.TRUE: 'True'>}\n",
      "00:23:09 INFO - pipeline id pipeline_id\n",
      "00:23:09 INFO - code location None\n",
      "00:23:09 INFO - data factory data_ is using local data access: input_folder - input output_folder - output/1-html2parquet\n",
      "00:23:09 INFO - data factory data_ max_files -1, n_sample -1\n",
      "00:23:09 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.html', '.zip'], files to checkpoint ['.parquet']\n",
      "00:23:09 INFO - orchestrator html2parquet started at 2024-11-26 00:23:09\n",
      "00:23:09 INFO - Number of files is 20, source profile {'max_file_size': 0.23515033721923828, 'min_file_size': 0.0885457992553711, 'total_file_size': 2.5425233840942383}\n",
      "00:23:10 INFO - Completed 1 files (5.0%) in 0.003 min\n",
      "00:23:10 INFO - Completed 2 files (10.0%) in 0.003 min\n",
      "00:23:10 INFO - Completed 3 files (15.0%) in 0.004 min\n",
      "00:23:10 INFO - Completed 4 files (20.0%) in 0.004 min\n",
      "00:23:10 INFO - Completed 5 files (25.0%) in 0.004 min\n",
      "00:23:10 INFO - Completed 6 files (30.0%) in 0.005 min\n",
      "00:23:10 INFO - Completed 7 files (35.0%) in 0.005 min\n",
      "00:23:10 INFO - Completed 8 files (40.0%) in 0.005 min\n",
      "00:23:10 INFO - Completed 9 files (45.0%) in 0.005 min\n",
      "00:23:10 INFO - Completed 10 files (50.0%) in 0.005 min\n",
      "00:23:10 INFO - Completed 11 files (55.0%) in 0.006 min\n",
      "00:23:10 INFO - Completed 12 files (60.0%) in 0.006 min\n",
      "00:23:10 INFO - Completed 13 files (65.0%) in 0.006 min\n",
      "00:23:10 INFO - Completed 14 files (70.0%) in 0.006 min\n",
      "00:23:10 INFO - Completed 15 files (75.0%) in 0.006 min\n",
      "00:23:10 INFO - Completed 16 files (80.0%) in 0.006 min\n",
      "00:23:10 INFO - Completed 17 files (85.0%) in 0.007 min\n",
      "00:23:10 INFO - Completed 18 files (90.0%) in 0.007 min\n",
      "00:23:10 INFO - Completed 19 files (95.0%) in 0.007 min\n",
      "00:23:10 INFO - Completed 20 files (100.0%) in 0.007 min\n",
      "00:23:10 INFO - Done processing 20 files, waiting for flush() completion.\n",
      "00:23:10 INFO - done flushing in 0.0 sec\n",
      "00:23:10 INFO - Completed execution in 0.007 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Job completed successfully\n",
      "CPU times: user 1.3 s, sys: 1.06 s, total: 2.36 s\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# from html2parquet_transform import Html2ParquetTransform, Html2ParquetTransformConfiguration\n",
    "from html2parquet_transform_python import Html2ParquetPythonTransformConfiguration\n",
    "from data_processing.runtime.pure_python import PythonTransformLauncher\n",
    "from data_processing.utils import GB, ParamsUtils\n",
    "\n",
    "\n",
    "local_conf = {\n",
    "    \"input_folder\": MY_CONFIG.INPUT_DIR,\n",
    "    \"output_folder\": MY_CONFIG.OUTPUT_DIR_HTML,\n",
    "}\n",
    "\n",
    "params =  {\n",
    "    \"data_files_to_use\": ast.literal_eval(\"['.html','.zip']\"),\n",
    "    \"html2parquet_output_format\": \"markdown\",\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "}\n",
    "\n",
    "sys.argv = ParamsUtils.dict_to_req(d=params)\n",
    "# launcher = PythonTransformLauncher(runtime_config=Html2ParquetTransformConfiguration())\n",
    "launcher = PythonTransformLauncher(runtime_config=Html2ParquetPythonTransformConfiguration())\n",
    "\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Job completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Inspect the Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensions (rows x columns)=  (20, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>document</th>\n",
       "      <th>contents</th>\n",
       "      <th>document_id</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thealliance_ai_blog-open-source-ai-demo-night-...</td>\n",
       "      <td>thealliance_ai_blog-open-source-ai-demo-night-...</td>\n",
       "      <td>On August 8th, The AI Alliance, in collaborati...</td>\n",
       "      <td>7802bb7e50653e6b21f571b28843fd9a4bcf5023eaab3a...</td>\n",
       "      <td>3151</td>\n",
       "      <td>2024-11-26T00:23:10.251906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thealliance_ai_core-projects-sb1047_text.html</td>\n",
       "      <td>thealliance_ai_core-projects-sb1047_text.html</td>\n",
       "      <td>The AI Alliance, a community of technology cre...</td>\n",
       "      <td>bbfed07faf040c9f276df43207437f0501cf9da14ec956...</td>\n",
       "      <td>7184</td>\n",
       "      <td>2024-11-26T00:23:10.303543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thealliance_ai_focus-areas-foundation-models-d...</td>\n",
       "      <td>thealliance_ai_focus-areas-foundation-models-d...</td>\n",
       "      <td># Open Foundation Models and Datasets\\n\\n### E...</td>\n",
       "      <td>cace8c007c2c65b7a92d9f152b7e012502b1614205e7c9...</td>\n",
       "      <td>4499</td>\n",
       "      <td>2024-11-26T00:23:10.341442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thealliance_ai_focus-areas-skills-education_te...</td>\n",
       "      <td>thealliance_ai_focus-areas-skills-education_te...</td>\n",
       "      <td># Skills &amp; Education\\n\\n### Supporting global ...</td>\n",
       "      <td>d98ef830df5e293bb7903e021b60194e8b4e529ef4824b...</td>\n",
       "      <td>334</td>\n",
       "      <td>2024-11-26T00:23:10.362269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thealliance_ai_focus-areas-applications-and-to...</td>\n",
       "      <td>thealliance_ai_focus-areas-applications-and-to...</td>\n",
       "      <td>![abstract gradient](https://images.prismic.io...</td>\n",
       "      <td>37752caba69be871c683c399ca2d5ab2afbec4d2623563...</td>\n",
       "      <td>568</td>\n",
       "      <td>2024-11-26T00:23:10.333829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  thealliance_ai_blog-open-source-ai-demo-night-...   \n",
       "1      thealliance_ai_core-projects-sb1047_text.html   \n",
       "2  thealliance_ai_focus-areas-foundation-models-d...   \n",
       "3  thealliance_ai_focus-areas-skills-education_te...   \n",
       "4  thealliance_ai_focus-areas-applications-and-to...   \n",
       "\n",
       "                                            document  \\\n",
       "0  thealliance_ai_blog-open-source-ai-demo-night-...   \n",
       "1      thealliance_ai_core-projects-sb1047_text.html   \n",
       "2  thealliance_ai_focus-areas-foundation-models-d...   \n",
       "3  thealliance_ai_focus-areas-skills-education_te...   \n",
       "4  thealliance_ai_focus-areas-applications-and-to...   \n",
       "\n",
       "                                            contents  \\\n",
       "0  On August 8th, The AI Alliance, in collaborati...   \n",
       "1  The AI Alliance, a community of technology cre...   \n",
       "2  # Open Foundation Models and Datasets\\n\\n### E...   \n",
       "3  # Skills & Education\\n\\n### Supporting global ...   \n",
       "4  ![abstract gradient](https://images.prismic.io...   \n",
       "\n",
       "                                         document_id  size  \\\n",
       "0  7802bb7e50653e6b21f571b28843fd9a4bcf5023eaab3a...  3151   \n",
       "1  bbfed07faf040c9f276df43207437f0501cf9da14ec956...  7184   \n",
       "2  cace8c007c2c65b7a92d9f152b7e012502b1614205e7c9...  4499   \n",
       "3  d98ef830df5e293bb7903e021b60194e8b4e529ef4824b...   334   \n",
       "4  37752caba69be871c683c399ca2d5ab2afbec4d2623563...   568   \n",
       "\n",
       "                date_acquired  \n",
       "0  2024-11-26T00:23:10.251906  \n",
       "1  2024-11-26T00:23:10.303543  \n",
       "2  2024-11-26T00:23:10.341442  \n",
       "3  2024-11-26T00:23:10.362269  \n",
       "4  2024-11-26T00:23:10.333829  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(MY_CONFIG.OUTPUT_DIR_HTML)\n",
    "\n",
    "print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(5)\n",
    "\n",
    "## To display certain columns\n",
    "#parquet_df[['column1', 'column2', 'column3']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thealliance_ai_blog-open-source-ai-demo-night-sf-2024_text.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.iloc[0,]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thealliance_ai_blog-open-source-ai-demo-night-sf-2024_text.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.iloc[0,]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content length: 3151 \n",
      "\n",
      "On August 8th, The AI Alliance, in collaboration with Cerebral Valley and Ollama, hosted Open Source AI Demo Night in San Francisco, bringing together more than 200+ developers and innovators to showcase and celebrate the latest advances in open-source AI. There were 7 demo teams and a panel discussion on [why open technologies and communities are essential to driving innovation in California](https://youtu.be/tOXzyHJvOKw).\n",
      "\n",
      "The demo teams included:\n",
      "\n",
      "[Ollama](https://ollama.com/)- helps developers run language models such as Llama 3.1, Mistral, Gemma 2, and others, locally on the computer or on a server cluster. Watch Michael Yang’s demo here:[Tool calling with Ollama - How an LLM accesses external information.](https://youtu.be/YWLLrgzzbj8)[Continue](https://www.continue.dev/)– a leading open-source AI code assistant that connects any models and any context to build custom autocomplete and chat experiences inside the IDE. Watch Ty Dunn’s demo here:[Using Continue to understand a brand new code library](https://youtu.be/BUq66FHVqng)[AgentOps](https://www.agentops.ai/)– an industry-leading developer platform to test and debug AI agents. Watch Alex Reibman and Ajay Poshak demo LlamaFS here:[LlamaFS: A self-organizing agentic filesystem](https://youtu.be/P3pND_JSkuQ)[CrewAI](https://www.crewai.com/)- Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.Watch João Moura’s demo here:[Build multi-agent automations with Crew.ai](https://youtu.be/5b07faElxfM).[Based Hardware](https://basedhardware.com/)– a fully open-source AI note taker that provides you with reminders, suggestions, and more; all in one simple app. Watch Nik Shevchenko’s demo here:[Friend: An AI necklace you wear which records your day](https://youtu.be/e0owdgDDP0I)[Datafog](https://www.datafog.ai/)– an open source AI/ML platform with solutions to scan unstructured content in files for PII, either annotating, anonymizing, or redacting sensitive information. Watch Sid Mohan’s demo here:[Using Open Source LLMs for PII data detection with DataFog](https://youtu.be/c1dx2bzaplk)[Semikong](https://www.semikong.ai/)- the World’s First Semiconductor Industry-Specific Large Language Model. Watch Nanda Kishore‘s demo here:[SemiKong: The Open Source Semiconductor LLM powered by Llama](https://youtu.be/zIhyFom_obM)\n",
      "\n",
      "\n",
      "Demo Night also featured a panel discussion “[AI in the Era of Open Innovation](https://youtu.be/tOXzyHJvOKw),” moderated by CEO & Founder Aitomatic Christopher Nguyen, and featured Matt White, Executive Director of PyTorch Foundation and General Manager of AI, Linux Foundation; Charles Xie, CEO of Zilliz; and Sharon Zhou, CEO of Lamini. The panelists underscored the importance of having access to state of the art open-source AI models in building their company by fine-tuning the models to their respective company needs. Moreover, the panelists opposed California Senate Bill 1047, highlighting that it would stifle open-source AI development and have a downstream chilling effect on AI investment and expansion.\n"
     ]
    }
   ],
   "source": [
    "## Display markdown text\n",
    "print ('content length:', len(output_df.iloc[0,]['contents']), '\\n')\n",
    "print (output_df.iloc[0,]['contents'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "On August 8th, The AI Alliance, in collaboration with Cerebral Valley and Ollama, hosted Open Source AI Demo Night in San Francisco, bringing together more than 200+ developers and innovators to showcase and celebrate the latest advances in open-source AI. There were 7 demo teams and a panel discussion on [why open technologies and communities are essential to driving innovation in California](https://youtu.be/tOXzyHJvOKw).\n",
       "\n",
       "The demo teams included:\n",
       "\n",
       "[Ollama](https://ollama.com/)- helps developers run language models such as Llama 3.1, Mistral, Gemma 2, and others, locally on the computer or on a server cluster. Watch Michael Yang’s demo here:[Tool calling with Ollama - How an LLM accesses external information.](https://youtu.be/YWLLrgzzbj8)[Continue](https://www.continue.dev/)– a leading open-source AI code assistant that connects any models and any context to build custom autocomplete and chat experiences inside the IDE. Watch Ty Dunn’s demo here:[Using Continue to understand a brand new code library](https://youtu.be/BUq66FHVqng)[AgentOps](https://www.agentops.ai/)– an industry-leading developer platform to test and debug AI agents. Watch Alex Reibman and Ajay Poshak demo LlamaFS here:[LlamaFS: A self-organizing agentic filesystem](https://youtu.be/P3pND_JSkuQ)[CrewAI](https://www.crewai.com/)- Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.Watch João Moura’s demo here:[Build multi-agent automations with Crew.ai](https://youtu.be/5b07faElxfM).[Based Hardware](https://basedhardware.com/)– a fully open-source AI note taker that provides you with reminders, suggestions, and more; all in one simple app. Watch Nik Shevchenko’s demo here:[Friend: An AI necklace you wear which records your day](https://youtu.be/e0owdgDDP0I)[Datafog](https://www.datafog.ai/)– an open source AI/ML platform with solutions to scan unstructured content in files for PII, either annotating, anonymizing, or redacting sensitive information. Watch Sid Mohan’s demo here:[Using Open Source LLMs for PII data detection with DataFog](https://youtu.be/c1dx2bzaplk)[Semikong](https://www.semikong.ai/)- the World’s First Semiconductor Industry-Specific Large Language Model. Watch Nanda Kishore‘s demo here:[SemiKong: The Open Source Semiconductor LLM powered by Llama](https://youtu.be/zIhyFom_obM)\n",
       "\n",
       "\n",
       "Demo Night also featured a panel discussion “[AI in the Era of Open Innovation](https://youtu.be/tOXzyHJvOKw),” moderated by CEO & Founder Aitomatic Christopher Nguyen, and featured Matt White, Executive Director of PyTorch Foundation and General Manager of AI, Linux Foundation; Charles Xie, CEO of Zilliz; and Sharon Zhou, CEO of Lamini. The panelists underscored the importance of having access to state of the art open-source AI models in building their company by fine-tuning the models to their respective company needs. Moreover, the panelists opposed California Senate Bill 1047, highlighting that it would stifle open-source AI development and have a downstream chilling effect on AI investment and expansion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## display markdown in pretty format\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(output_df.iloc[0,]['contents']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Save the markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 20 md files into 'output/2-markdown'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for index, row in output_df.iterrows():\n",
    "    html_file = row['document']\n",
    "    base_name = os.path.splitext(os.path.basename(html_file))[0]\n",
    "    md_output_file = os.path.join(MY_CONFIG.OUTPUT_DIR_MARKDOWN, base_name +  '.md')\n",
    "    \n",
    "    with open(md_output_file, 'w') as md_output_file_handle:\n",
    "        md_output_file_handle.write (row['contents'])\n",
    "# -- end loop ---       \n",
    "\n",
    "print (f\"✅ Saved {index+1} md files into '{MY_CONFIG.OUTPUT_DIR_MARKDOWN}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpk-html-processing-2-022dev3-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
