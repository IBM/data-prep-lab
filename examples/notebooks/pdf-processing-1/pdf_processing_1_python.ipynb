{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841e533d-ebb3-406d-9da7-b19e2c5f5866",
   "metadata": {
    "id": "841e533d-ebb3-406d-9da7-b19e2c5f5866"
   },
   "source": [
    "# Processing PDFs using Data Prep Kit\n",
    "\n",
    "This notebook will introduce DPK and showcase some of it's capabilities.\n",
    "\n",
    "Here is the workflow:\n",
    "\n",
    "- pdf2parquet: Extract text from PDF documents\n",
    "- docid: compute hashes\n",
    "- exact dedupe : filter out identical documents\n",
    "- fuzzy dedupe : filter out 'near duplicates'\n",
    "- document quality: scoring documents for quality\n",
    "\n",
    "![](https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/images/data-prep-kit-3-workflow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15976e3",
   "metadata": {
    "id": "b15976e3"
   },
   "source": [
    "## How to run this notebook\n",
    "\n",
    "Two options:\n",
    "\n",
    "- **Option 1 - Google Colab:** easiest option.  no setup required.  Click this link to open this on google colab.  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/dpk_intro_1_python.ipynb)\n",
    "- **Option 2 - Local python dev environment:**  Setup using this [guide](../../../README.md#-getting-started)\n",
    "\n",
    "The notebook will work as in both environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0ab6e",
   "metadata": {
    "id": "39a0ab6e"
   },
   "source": [
    "## Step-1: Figure out Runtime Environment\n",
    "\n",
    "### 1.1 - Determine runtime\n",
    "\n",
    "Determine if we are running on Google colab or local python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe354b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fe354b7",
    "outputId": "5c153f72-08ed-4d6e-ccc7-dae851e7fd8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT in Colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   print(\"Running in Colab\")\n",
    "   RUNNING_IN_COLAB = True\n",
    "else:\n",
    "   print(\"NOT in Colab\")\n",
    "   RUNNING_IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc2b68",
   "metadata": {
    "id": "a5dc2b68"
   },
   "source": [
    "### 1.2 - Install dependencies if running on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fcec577",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1fcec577",
    "outputId": "0f77fc39-ffeb-48da-ce6f-1750d8d3ad62"
   },
   "outputs": [],
   "source": [
    "if RUNNING_IN_COLAB:\n",
    "    ! pip install  --default-timeout=100  \\\n",
    "        data-prep-toolkit-transforms[ray,all]==1.0.0a4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243322b8",
   "metadata": {
    "id": "243322b8"
   },
   "source": [
    "### 1.3 - Restart Runtime\n",
    "\n",
    "After installing dependencies, be sure <font color=\"red\">restart runtime</font>, so libraries will be loaded\n",
    "\n",
    "You do this by going to **`Runtime --> Restart Session`**\n",
    "\n",
    "Then you can continue to the next step (no need to re-run the notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b10be1",
   "metadata": {
    "id": "e8b10be1"
   },
   "source": [
    "## Step-2: Configuration  & Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c66f7",
   "metadata": {
    "id": "356c66f7"
   },
   "source": [
    "### 2.1 - Basic Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4YMZrBuFycl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4YMZrBuFycl",
    "outputId": "d7ee9449-4f21-4c9a-fa54-14b7f28d764a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT in Colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   print(\"Running in Colab\")\n",
    "   RUNNING_IN_COLAB = True\n",
    "else:\n",
    "   print(\"NOT in Colab\")\n",
    "   RUNNING_IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72510ae6-48b0-4b88-9e13-a623281c3a63",
   "metadata": {
    "id": "72510ae6-48b0-4b88-9e13-a623281c3a63"
   },
   "source": [
    "### 2.2 - Setup input/outpur directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ac8bee-0960-4309-b225-d7a211b14262",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60ac8bee-0960-4309-b225-d7a211b14262",
    "outputId": "4d5511fb-1c6f-47df-e5ea-2c1b354d262f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleared output directory\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "input_dir = \"input\"\n",
    "shutil.os.makedirs(input_dir, exist_ok=True)\n",
    "output_dir = \"output\"\n",
    "\n",
    "output_text_dir = os.path.join (output_dir, '01_text_out')\n",
    "output_docid_dir = os.path.join (output_dir, '02_docid_out')\n",
    "output_exact_dedupe_dir = os.path.join (output_dir, '03_exact_dedupe_out')\n",
    "output_fuzzy_dedupe_dir = os.path.join (output_dir, '04_fuzzy_dedupe_out')\n",
    "output_doc_quality_dir = os.path.join (output_dir, '05_doc_quality_out')\n",
    "output_final_dir = os.path.join (output_dir, 'output_final')\n",
    "\n",
    "## clear output folder\n",
    "shutil.rmtree(output_dir, ignore_errors=True)\n",
    "shutil.os.makedirs(output_dir, exist_ok=True)\n",
    "print (\"✅ Cleared output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2f34c",
   "metadata": {},
   "source": [
    "### 2.3 - Handy Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba47a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from humanfriendly import format_size\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "## Reads parquet files in a folder into a pandas dataframe\n",
    "def read_parquet_files_as_df (parquet_dir):\n",
    "    parquet_files = glob.glob(f'{parquet_dir}/*.parquet')\n",
    "    # read each parquet file into a DataFrame and store in a list\n",
    "    dfs = [pd.read_parquet (f) for f in parquet_files]\n",
    "    dfs = [df for df in dfs if not df.empty]  # filter out empty dataframes\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    if len(dfs) > 0:\n",
    "        data_df = pd.concat(dfs, ignore_index=True)\n",
    "        return data_df\n",
    "    else:\n",
    "        return pd.DataFrame() # return empty df\n",
    "# ------------\n",
    "\n",
    "\n",
    "def download_file(url, local_file, chunk_size=1024*1024):\n",
    "    \"\"\"\n",
    "    Downloads a remote URL to a local file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The remote URL.\n",
    "        local_filename (str): The name of the local file to save the downloaded content.\n",
    "        chunk_size (int): The size in bytes of each chunk. Defaults to 1024.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Example usage:\n",
    "        download_file('http://example.com/file.txt', 'file.txt', chunk_size=1024*1024)  # Download in chunks of 1MB\n",
    "    \"\"\"\n",
    "    # Check if the local file already exists\n",
    "    if os.path.exists(local_file):\n",
    "        file_size = format_size(os.path.getsize(local_file))\n",
    "        print(f\"Local file '{local_file}' ({file_size}) already exists. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "\n",
    "    # Stream the file download\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "        print()\n",
    "        file_size = format_size(os.path.getsize(local_file))\n",
    "        print(f\"{local_file} ({file_size}) downloaded successfully.\")\n",
    "## --- end: download_file ------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1972c3",
   "metadata": {},
   "source": [
    "## Step-3: Inspect the Data\n",
    "\n",
    "We will use simple PDFs.  The files are [here](https://github.com/IBM/data-prep-kit/tree/dev/examples/notebooks/pdf-processing-1/input/)\n",
    "\n",
    "- [earth.pdf](https://github.com/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/input/earth.pdf) and exact duplicate [earth-copy.pdf](https://github.com/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/input/earth-copy.pdf)\n",
    "- [earth2.pdf](https://github.com/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/input/earth2.pdf) almost similar to earth.pdf (ONE word difference!)\n",
    "- [mars.pdf](https://github.com/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/input/mars.pdf)\n",
    "- [spam.pdf](https://github.com/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/input/spam.pdf) - contains spammy contents\n",
    "- [lorem.pdf](https://github.com/IBM/data-prep-kit/blob/dev/examples/notebooks/pdf-processing-1/input/lorem.pdf) - contains 'lorem ipsum' placeholder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113b16c",
   "metadata": {},
   "source": [
    "### 3.1 -Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23db1064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local file 'input/earth.pdf' (58.53 KB) already exists. Skipping download.\n",
      "Local file 'input/earth-copy.pdf' (58.53 KB) already exists. Skipping download.\n",
      "Local file 'input/earth2.pdf' (58.53 KB) already exists. Skipping download.\n",
      "Local file 'input/mars.pdf' (57.87 KB) already exists. Skipping download.\n",
      "Local file 'input/spam.pdf' (24.87 KB) already exists. Skipping download.\n",
      "Local file 'input/lorem-ipsum.pdf' (25.72 KB) already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "download_file ('https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/input/earth.pdf', os.path.join(input_dir, 'earth.pdf'))\n",
    "\n",
    "download_file ('https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/input/earth-copy.pdf', os.path.join(input_dir, 'earth-copy.pdf'))\n",
    "\n",
    "download_file ('https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/input/earth2.pdf', os.path.join(input_dir, 'earth2.pdf'))\n",
    "\n",
    "download_file ('https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/input/mars.pdf', os.path.join(input_dir, 'mars.pdf'))\n",
    "\n",
    "download_file ('https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/input/spam.pdf', os.path.join(input_dir, 'spam.pdf'))\n",
    "\n",
    "download_file ('https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/pdf-processing-1/input/lorem-ipsum.pdf', os.path.join(input_dir, 'lorem-ipsum.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449e5c7-078c-4ad6-a2f6-21d39d4da3fb",
   "metadata": {
    "id": "2449e5c7-078c-4ad6-a2f6-21d39d4da3fb"
   },
   "source": [
    "## Step-4: Extract Data from PDF (pdf2parquet)\n",
    "\n",
    "This step we will read PDF files and extract the text data.\n",
    "\n",
    "[Pdf2Parquet documentation](https://github.com/IBM/data-prep-kit/blob/dev/transforms/language/pdf2parquet/README.md)\n",
    "\n",
    "We use the [Docling package](https://github.com/DS4SD/docling).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb15f02-ab5c-4525-a536-cfa1fd2ba70b",
   "metadata": {
    "id": "9bb15f02-ab5c-4525-a536-cfa1fd2ba70b"
   },
   "source": [
    "### 4.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cd8ebd-bf71-42d6-a397-8df0c7b66a26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657,
     "referenced_widgets": [
      "97b603697cfa4b4ea4e6735b6768ca35",
      "e87e8d3262c54cfaaa8768505edacda3",
      "b78aa40816e44f7fbebcb24ca68818b3",
      "7053c9606a414e978636a7e241909504",
      "da0787b239764847a731083997780a85",
      "553f3c16839a49d79591d0fc4862bed6",
      "c0eb5bc8f6ee427ca42204b3c56f9a4e",
      "9d184ed175f0403fb03c2e13dfd04e0a",
      "724778729161445c98b187031ae4f67c",
      "1cb3bbf7d724411cbe9831543a4aecc0",
      "06f9b33494984e4885d5aad813d1d2bc"
     ]
    },
    "id": "b0cd8ebd-bf71-42d6-a397-8df0c7b66a26",
    "outputId": "01d207fb-983d-40b2-e5f6-e38e3789110a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-1: Processing input='input' --> output='output/01_text_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:43:57 INFO - pdf2parquet parameters are : {'batch_size': -1, 'artifacts_path': None, 'contents_type': <pdf2parquet_contents_types.MARKDOWN: 'text/markdown'>, 'do_table_structure': True, 'do_ocr': True, 'ocr_engine': <pdf2parquet_ocr_engine.EASYOCR: 'easyocr'>, 'bitmap_area_threshold': 0.05, 'pdf_backend': <pdf2parquet_pdf_backend.DLPARSE_V2: 'dlparse_v2'>, 'double_precision': 8}\n",
      "23:43:57 INFO - pipeline id pipeline_id\n",
      "23:43:57 INFO - code location None\n",
      "23:43:57 INFO - data factory data_ is using local data access: input_folder - input output_folder - output/01_text_out\n",
      "23:43:57 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:43:57 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.pdf'], files to checkpoint ['.parquet']\n",
      "23:43:57 INFO - orchestrator pdf2parquet started at 2025-01-21 23:43:57\n",
      "23:43:57 INFO - Number of files is 6, source profile {'max_file_size': 0.055823326110839844, 'min_file_size': 0.023715972900390625, 'total_file_size': 0.2709054946899414}\n",
      "23:43:57 INFO - Initializing models\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 112347.43it/s]\n",
      "23:44:01 INFO - Completed 1 files (16.67%) in 0.017 min\n",
      "23:44:02 INFO - Completed 2 files (33.33%) in 0.031 min\n",
      "23:44:03 INFO - Completed 3 files (50.0%) in 0.042 min\n",
      "23:44:04 INFO - Completed 4 files (66.67%) in 0.052 min\n",
      "23:44:04 INFO - Completed 5 files (83.33%) in 0.063 min\n",
      "23:44:05 INFO - Completed 6 files (100.0%) in 0.073 min\n",
      "23:44:05 INFO - Done processing 6 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.126 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:1 completed successfully\n",
      "CPU times: user 20.3 s, sys: 1.99 s, total: 22.3 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_pdf2parquet.transform_python import Pdf2Parquet\n",
    "from dpk_pdf2parquet.transform import pdf2parquet_contents_types\n",
    "\n",
    "STAGE = 1 \n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{input_dir}' --> output='{output_text_dir}'\\n\", flush=True)\n",
    "\n",
    "result = Pdf2Parquet(input_folder= input_dir,\n",
    "                    output_folder= output_text_dir,\n",
    "                    data_files_to_use=['.pdf'],\n",
    "                    pdf2parquet_contents_type=pdf2parquet_contents_types.MARKDOWN,   # markdown\n",
    "                    #    pdf2parquet_contents_type=pdf2parquet_contents_types.JSON   # JSON\n",
    "                    ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"❌ Stage:{STAGE}  failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca790e0",
   "metadata": {
    "id": "5ca790e0"
   },
   "source": [
    "### 4.2 - Inspect Generated output\n",
    "\n",
    "Here we should see one entry per input file processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe59563d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "fe59563d",
    "outputId": "346e0584-bdde-4705-8c2a-f3c1582cd7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying contents of :  output/01_text_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b</td>\n",
       "      <td>6571294142213095721</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-01-21T23:44:04.067075</td>\n",
       "      <td>0.636751</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>518a2e39-5c85-400f-8864-6bbc3ef20b1e</td>\n",
       "      <td>10026122586747302274</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-01-21T23:44:05.320766</td>\n",
       "      <td>0.619056</td>\n",
       "      <td>spam.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earth2.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>c9accf02-d2ed-4307-b0c4-53a3a3699179</td>\n",
       "      <td>10729312978404042321</td>\n",
       "      <td>pdf</td>\n",
       "      <td>f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:03.428640</td>\n",
       "      <td>0.620741</td>\n",
       "      <td>earth2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>## Mars\\n\\n## Solar System\\n\\nOur solar system...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4</td>\n",
       "      <td>7758129997476962679</td>\n",
       "      <td>pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>717</td>\n",
       "      <td>2025-01-21T23:44:04.700038</td>\n",
       "      <td>0.629441</td>\n",
       "      <td>mars.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>b895a249-e72d-4096-85fa-e0606d61aebf</td>\n",
       "      <td>14711865278795535908</td>\n",
       "      <td>pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:01.917104</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>earth-copy.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                           contents  \\\n",
       "0  lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "1         spam.pdf                                           Free xxx   \n",
       "2       earth2.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "3         mars.pdf  ## Mars\\n\\n## Solar System\\n\\nOur solar system...   \n",
       "4   earth-copy.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0          1           0                 2   \n",
       "1          1           0                 2   \n",
       "2          1           0                11   \n",
       "3          1           0                11   \n",
       "4          1           0                11   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b   6571294142213095721  pdf   \n",
       "1  518a2e39-5c85-400f-8864-6bbc3ef20b1e  10026122586747302274  pdf   \n",
       "2  c9accf02-d2ed-4307-b0c4-53a3a3699179  10729312978404042321  pdf   \n",
       "3  37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4   7758129997476962679  pdf   \n",
       "4  b895a249-e72d-4096-85fa-e0606d61aebf  14711865278795535908  pdf   \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...    35   \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...     8   \n",
       "2  f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...   610   \n",
       "3  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...   717   \n",
       "4  6140cf695f269a3ddca6568536076756105ad3186086b2...   610   \n",
       "\n",
       "                date_acquired  pdf_convert_time  source_filename  \n",
       "0  2025-01-21T23:44:04.067075          0.636751  lorem-ipsum.pdf  \n",
       "1  2025-01-21T23:44:05.320766          0.619056         spam.pdf  \n",
       "2  2025-01-21T23:44:03.428640          0.620741       earth2.pdf  \n",
       "3  2025-01-21T23:44:04.700038          0.629441         mars.pdf  \n",
       "4  2025-01-21T23:44:01.917104          0.993879   earth-copy.pdf  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Displaying contents of : \", output_text_dir)\n",
    "output_df = read_parquet_files_as_df(output_text_dir)\n",
    "# print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "output_df.head()\n",
    "\n",
    "## To display certain columns\n",
    "#parquet_df[['column1', 'column2', 'column3']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5058a21",
   "metadata": {
    "id": "e5058a21"
   },
   "source": [
    "\n",
    "### 4.3 - Understand the output\n",
    "\n",
    "Here are some interesting attributes to note:\n",
    "\n",
    "- **filename** : original filename\n",
    "- **contents** : text\n",
    "- **document_id**: unique id (UUID) assignd to this document\n",
    "- **document_hash**: hash of documents\n",
    "- **hash** : hash of `contents` column\n",
    "- **pdf_convert_time** : time to convert this pdf in seconds\n",
    "\n",
    "**Note: you should notice the hash values are identical for the duplicate documents**\n",
    "\n",
    "Let's inspect the **contents** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f870e624",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f870e624",
    "outputId": "0b4c054f-3a8a-4db3-f32f-17bd1466b102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum Lorem ipsum Lorem ipsum\n"
     ]
    }
   ],
   "source": [
    "print (output_df.iloc[0, ]['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a10c2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1a10c2d",
    "outputId": "c1d992c2-faa8-40cd-c375-857970201daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free xxx\n"
     ]
    }
   ],
   "source": [
    "print (output_df.iloc[1, ]['contents'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc86d5b",
   "metadata": {},
   "source": [
    "## Step-5:  Create DOC ID for Documents\n",
    "\n",
    "This transform annotates documents with document \"ids\". It supports the following transformations of the original data:\n",
    "\n",
    " - Adding document hash: this enables the addition of a document hash-based id to the data. The hash is calculated with `hashlib.sha256(doc.encode(\"utf-8\")).hexdigest()`. To enable this annotation, set **hash_column** to the name of the column, where you want to store it.\n",
    " - Adding integer document id: this allows the addition of an integer document id to the data that is unique across all rows in all tables provided to the transform() method. To enable this annotation, set **int_id_column** to the name of the column, where you want to store it.\n",
    "\n",
    "**This step is a pre-requisite for fuzzy dedup** in the pipeline.\n",
    "\n",
    "[DocID documentation](https://github.com/IBM/data-prep-kit/tree/dev/transforms/universal/doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f516a253",
   "metadata": {},
   "source": [
    "### 5.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee20521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-2: Processing input='output/01_text_out' --> output='output/02_docid_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:44:05 INFO - Doc id parameters are : {'doc_column': 'contents', 'hash_column': 'doc_hash', 'int_column': 'int_id_column', 'start_id': 0}\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/01_text_out output_folder - output/02_docid_out\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator doc_id started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of files is 6, source profile {'max_file_size': 0.010061264038085938, 'min_file_size': 0.0055408477783203125, 'total_file_size': 0.04969310760498047}\n",
      "23:44:05 INFO - Completed 1 files (16.67%) in 0.0 min\n",
      "23:44:05 INFO - Completed 2 files (33.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 3 files (50.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 4 files (66.67%) in 0.0 min\n",
      "23:44:05 INFO - Completed 5 files (83.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 6 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 6 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.0 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:2 completed successfully\n",
      "CPU times: user 15 ms, sys: 8.25 ms, total: 23.3 ms\n",
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_doc_id.transform_python import DocID\n",
    "\n",
    "STAGE = 2\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{output_text_dir}' --> output='{output_docid_dir}'\\n\", flush=True)\n",
    "\n",
    "result = DocID(input_folder= output_text_dir,\n",
    "        output_folder= output_docid_dir,\n",
    "        doc_id_doc_column= \"contents\",\n",
    "        doc_id_hash_column= \"doc_hash\",\n",
    "        # doc_id_int_column= \"doc_id\",\n",
    "        doc_id_int_column= \"int_id_column\",\n",
    "        #doc_id_start_id= 5\n",
    "        ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"❌ Stage:{STAGE}  failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd6f382",
   "metadata": {},
   "source": [
    "### 5.2 - Inspect Generated output\n",
    "\n",
    "You would see a new columns **hash** and **docid** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d4aba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying contents of :  output/02_docid_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>int_id_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b</td>\n",
       "      <td>6571294142213095721</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-01-21T23:44:04.067075</td>\n",
       "      <td>0.636751</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>518a2e39-5c85-400f-8864-6bbc3ef20b1e</td>\n",
       "      <td>10026122586747302274</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-01-21T23:44:05.320766</td>\n",
       "      <td>0.619056</td>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earth2.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>c9accf02-d2ed-4307-b0c4-53a3a3699179</td>\n",
       "      <td>10729312978404042321</td>\n",
       "      <td>pdf</td>\n",
       "      <td>f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:03.428640</td>\n",
       "      <td>0.620741</td>\n",
       "      <td>earth2.pdf</td>\n",
       "      <td>f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>## Mars\\n\\n## Solar System\\n\\nOur solar system...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4</td>\n",
       "      <td>7758129997476962679</td>\n",
       "      <td>pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>717</td>\n",
       "      <td>2025-01-21T23:44:04.700038</td>\n",
       "      <td>0.629441</td>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>b895a249-e72d-4096-85fa-e0606d61aebf</td>\n",
       "      <td>14711865278795535908</td>\n",
       "      <td>pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:01.917104</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                           contents  \\\n",
       "0  lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "1         spam.pdf                                           Free xxx   \n",
       "2       earth2.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "3         mars.pdf  ## Mars\\n\\n## Solar System\\n\\nOur solar system...   \n",
       "4   earth-copy.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0          1           0                 2   \n",
       "1          1           0                 2   \n",
       "2          1           0                11   \n",
       "3          1           0                11   \n",
       "4          1           0                11   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b   6571294142213095721  pdf   \n",
       "1  518a2e39-5c85-400f-8864-6bbc3ef20b1e  10026122586747302274  pdf   \n",
       "2  c9accf02-d2ed-4307-b0c4-53a3a3699179  10729312978404042321  pdf   \n",
       "3  37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4   7758129997476962679  pdf   \n",
       "4  b895a249-e72d-4096-85fa-e0606d61aebf  14711865278795535908  pdf   \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...    35   \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...     8   \n",
       "2  f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...   610   \n",
       "3  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...   717   \n",
       "4  6140cf695f269a3ddca6568536076756105ad3186086b2...   610   \n",
       "\n",
       "                date_acquired  pdf_convert_time  source_filename  \\\n",
       "0  2025-01-21T23:44:04.067075          0.636751  lorem-ipsum.pdf   \n",
       "1  2025-01-21T23:44:05.320766          0.619056         spam.pdf   \n",
       "2  2025-01-21T23:44:03.428640          0.620741       earth2.pdf   \n",
       "3  2025-01-21T23:44:04.700038          0.629441         mars.pdf   \n",
       "4  2025-01-21T23:44:01.917104          0.993879   earth-copy.pdf   \n",
       "\n",
       "                                            doc_hash  int_id_column  \n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...              3  \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...              5  \n",
       "2  f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...              2  \n",
       "3  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...              4  \n",
       "4  6140cf695f269a3ddca6568536076756105ad3186086b2...              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Displaying contents of : \", output_docid_dir)\n",
    "output_df = read_parquet_files_as_df(output_docid_dir)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f8d3f",
   "metadata": {},
   "source": [
    "## Step-6: Eliminate Duplicate Documents\n",
    "\n",
    "We have 2 exact duplicates: **earth.pdf** , **earth-copy.pdf**\n",
    "\n",
    "Note how **doc_hash** for these documents are the same.\n",
    "\n",
    "[Exact dedupe information](https://github.com/IBM/data-prep-kit/tree/dev/transforms/universal/ededup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ef1f7",
   "metadata": {},
   "source": [
    "### 6.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90eddb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-3: Processing input='output/02_docid_out' --> output='output/03_exact_dedupe_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:44:05 INFO - exact dedup params are {'doc_column': 'contents', 'doc_id_column': 'doc_hash', 'use_snapshot': False, 'snapshot_directory': None}\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/02_docid_out output_folder - output/03_exact_dedupe_out\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator ededup started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of files is 6, source profile {'max_file_size': 0.01116180419921875, 'min_file_size': 0.006641387939453125, 'total_file_size': 0.056290626525878906}\n",
      "23:44:05 INFO - Starting from the beginning\n",
      "23:44:05 INFO - Completed 1 files (16.67%) in 0.0 min\n",
      "23:44:05 INFO - Completed 2 files (33.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 3 files (50.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 4 files (66.67%) in 0.0 min\n",
      "23:44:05 INFO - Completed 5 files (83.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 6 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 6 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.0 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:3 completed successfully\n",
      "CPU times: user 20.5 ms, sys: 5.55 ms, total: 26.1 ms\n",
      "Wall time: 20.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_ededup.transform_python import Ededup\n",
    "\n",
    "STAGE = 3\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{output_docid_dir}' --> output='{output_exact_dedupe_dir}'\\n\", flush=True)\n",
    "\n",
    "result = Ededup(input_folder=output_docid_dir,\n",
    "    output_folder=output_exact_dedupe_dir,\n",
    "    ededup_doc_column=\"contents\",\n",
    "    ededup_doc_id_column=\"doc_hash\"\n",
    "    ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"❌ Stage:{STAGE}  failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aacf09",
   "metadata": {},
   "source": [
    "### 6.2 - Inspect Generated output\n",
    "\n",
    "You can see one of **earth.pdf** or **earth-copy.pdf** will be eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1887b26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files before exact dedupe : 6\n",
      "Output files after exact dedupe : 5\n",
      "Duplicate files removed :   1\n",
      "Displaying contents of :  output/03_exact_dedupe_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>int_id_column</th>\n",
       "      <th>removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b</td>\n",
       "      <td>6571294142213095721</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-01-21T23:44:04.067075</td>\n",
       "      <td>0.636751</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>518a2e39-5c85-400f-8864-6bbc3ef20b1e</td>\n",
       "      <td>10026122586747302274</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-01-21T23:44:05.320766</td>\n",
       "      <td>0.619056</td>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earth2.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>c9accf02-d2ed-4307-b0c4-53a3a3699179</td>\n",
       "      <td>10729312978404042321</td>\n",
       "      <td>pdf</td>\n",
       "      <td>f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:03.428640</td>\n",
       "      <td>0.620741</td>\n",
       "      <td>earth2.pdf</td>\n",
       "      <td>f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>## Mars\\n\\n## Solar System\\n\\nOur solar system...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4</td>\n",
       "      <td>7758129997476962679</td>\n",
       "      <td>pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>717</td>\n",
       "      <td>2025-01-21T23:44:04.700038</td>\n",
       "      <td>0.629441</td>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>b895a249-e72d-4096-85fa-e0606d61aebf</td>\n",
       "      <td>14711865278795535908</td>\n",
       "      <td>pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:01.917104</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                           contents  \\\n",
       "0  lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "1         spam.pdf                                           Free xxx   \n",
       "2       earth2.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "3         mars.pdf  ## Mars\\n\\n## Solar System\\n\\nOur solar system...   \n",
       "4   earth-copy.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0          1           0                 2   \n",
       "1          1           0                 2   \n",
       "2          1           0                11   \n",
       "3          1           0                11   \n",
       "4          1           0                11   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b   6571294142213095721  pdf   \n",
       "1  518a2e39-5c85-400f-8864-6bbc3ef20b1e  10026122586747302274  pdf   \n",
       "2  c9accf02-d2ed-4307-b0c4-53a3a3699179  10729312978404042321  pdf   \n",
       "3  37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4   7758129997476962679  pdf   \n",
       "4  b895a249-e72d-4096-85fa-e0606d61aebf  14711865278795535908  pdf   \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...    35   \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...     8   \n",
       "2  f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...   610   \n",
       "3  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...   717   \n",
       "4  6140cf695f269a3ddca6568536076756105ad3186086b2...   610   \n",
       "\n",
       "                date_acquired  pdf_convert_time  source_filename  \\\n",
       "0  2025-01-21T23:44:04.067075          0.636751  lorem-ipsum.pdf   \n",
       "1  2025-01-21T23:44:05.320766          0.619056         spam.pdf   \n",
       "2  2025-01-21T23:44:03.428640          0.620741       earth2.pdf   \n",
       "3  2025-01-21T23:44:04.700038          0.629441         mars.pdf   \n",
       "4  2025-01-21T23:44:01.917104          0.993879   earth-copy.pdf   \n",
       "\n",
       "                                            doc_hash  int_id_column removed  \n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...              3      []  \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...              5      []  \n",
       "2  f039191d59ce8ba25023a844f9b99e7ef2ea4bf75a23f4...              2      []  \n",
       "3  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...              4      []  \n",
       "4  6140cf695f269a3ddca6568536076756105ad3186086b2...              0      []  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = read_parquet_files_as_df(output_docid_dir)\n",
    "output_df = read_parquet_files_as_df(output_exact_dedupe_dir)\n",
    "\n",
    "# print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "# print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "print (f\"Input files before exact dedupe : {input_df.shape[0]:,}\")\n",
    "print (f\"Output files after exact dedupe : {output_df.shape[0]:,}\")\n",
    "print (\"Duplicate files removed :  \", (input_df.shape[0] - output_df.shape[0]))\n",
    "\n",
    "print (\"Displaying contents of : \", output_exact_dedupe_dir)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea34e2",
   "metadata": {},
   "source": [
    "## Step-7: Fuzzy Dedupe\n",
    "\n",
    "In previous step, we removed **exact duplicates (identical documents)**.\n",
    "\n",
    "Fuzzy de-dupe can further filter out documents that are **not exactly identical, but nearly identical**\n",
    "\n",
    "For example imagine two documents with one extra blank line.  For our purposes they are the same.\n",
    "\n",
    "[Fuzzy dedupe documentation](https://github.com/IBM/data-prep-kit/tree/dev/transforms/universal/fdedup)\n",
    "\n",
    "### Tweaking the threshold\n",
    "\n",
    "**`jaccard_similarity_threshold`** is the parameter used to tweak similarities between documents.  It's value is between 0 and 1.0.  Values close to 1.0 means more strict checking (fewer documents will qualify).  Lower threshold means more leniant matches (more documents will qualify)\n",
    "\n",
    "Adjust this value to find what works for your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a37713",
   "metadata": {},
   "source": [
    "### 7.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37430b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-4: Processing input='output/03_exact_dedupe_out' --> output='output/04_fuzzy_dedupe_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:44:05 INFO - Starting SignatureCalculation step\n",
      "23:44:05 INFO - Got parameters for SignatureCalculation\n",
      "23:44:05 INFO - minhash parameters are : {'document_id_column': 'int_id_column', 'contents_column': 'contents', 'seed': 42, 'num_permutations': 112, 'jaccard_similarity_threshold': 0.8, 'word_shingle_size': 5, 'num_bands': 14, 'num_minhashes_per_band': 8, 'num_segments': 1, 'shingle_option': 'word'}\n",
      "23:44:05 INFO - data factory scdata_ is using local configuration without input/output path\n",
      "23:44:05 INFO - data factory scdata_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory scdata_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/03_exact_dedupe_out output_folder - output/04_fuzzy_dedupe_out\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator minhash started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of files is 6, source profile {'max_file_size': 0.011510848999023438, 'min_file_size': 0.003223419189453125, 'total_file_size': 0.050751686096191406}\n",
      "23:44:05 INFO - Completed 1 files (16.67%) in 0.0 min\n",
      "23:44:05 WARNING - table is empty, skipping processing\n",
      "23:44:05 INFO - Completed 2 files (33.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 3 files (50.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 4 files (66.67%) in 0.0 min\n",
      "23:44:05 INFO - Completed 5 files (83.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 6 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 6 files, waiting for flush() completion.\n",
      "23:44:05 INFO - Starting flush()\n",
      "23:44:05 INFO - Wrote 14 tables with a total size of 33,600 bytes\n",
      "23:44:05 INFO - done flushing in 0.021 sec\n",
      "23:44:05 INFO - Completed execution in 0.001 min, execution result 0\n",
      "23:44:05 INFO - SignatureCalculation completed successfully\n",
      "23:44:05 INFO - Starting ClusterAnalysis step\n",
      "23:44:05 INFO - Got parameters for ClusterAnalysis\n",
      "23:44:05 INFO - cluster parameters are : {'jaccard_similarity_threshold': 0.8, 'num_bands': 14, 'num_segments': 1, 'sort_output': False}\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/04_fuzzy_dedupe_out/bands output_folder - output/04_fuzzy_dedupe_out/docs_to_remove\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator cluster started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of folders is 14\n",
      "23:44:05 INFO - Completed 1 files (7.14%) in 0.0 min\n",
      "23:44:05 INFO - Completed 2 files (14.29%) in 0.0 min\n",
      "23:44:05 INFO - Completed 3 files (21.43%) in 0.0 min\n",
      "23:44:05 INFO - Completed 4 files (28.57%) in 0.0 min\n",
      "23:44:05 INFO - Completed 5 files (35.71%) in 0.0 min\n",
      "23:44:05 INFO - Completed 6 files (42.86%) in 0.0 min\n",
      "23:44:05 INFO - Completed 7 files (50.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 8 files (57.14%) in 0.0 min\n",
      "23:44:05 INFO - Completed 9 files (64.29%) in 0.0 min\n",
      "23:44:05 INFO - Completed 10 files (71.43%) in 0.0 min\n",
      "23:44:05 INFO - Completed 11 files (78.57%) in 0.0 min\n",
      "23:44:05 INFO - Completed 12 files (85.71%) in 0.0 min\n",
      "23:44:05 INFO - Completed 13 files (92.86%) in 0.0 min\n",
      "23:44:05 INFO - Completed 14 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 14 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.0 min, execution result 0\n",
      "23:44:05 INFO - ClusterAnalysis completed successfully\n",
      "23:44:05 INFO - Starting GetDuplicateList step\n",
      "23:44:05 INFO - Got parameters for GetDuplicateList\n",
      "23:44:05 INFO - fdlist parameters are : {'docs_to_remove': 'docs_to_remove', 'consolidated_filename': 'docs_to_remove_consolidated/docs_to_remove_consolidated.parquet', 'sort_output': False}\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/04_fuzzy_dedupe_out output_folder - output/04_fuzzy_dedupe_out\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator fdlist started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of folders is 1\n",
      "23:44:05 INFO - Get Duplicate List for folder docs_to_remove\n",
      "23:44:05 INFO - 1 documents marked as duplicates\n",
      "23:44:05 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.0 min, execution result 0\n",
      "23:44:05 INFO - GetDuplicateList completed successfully\n",
      "23:44:05 INFO - Starting DataCleaning step\n",
      "23:44:05 INFO - Got parameters for DataCleaning\n",
      "23:44:05 INFO - fdclean parameters are : {'document_id_column': 'int_id_column', 'duplicate_list_location': 'docs_to_remove_consolidated/docs_to_remove_consolidated.parquet', 'operation_mode': 'filter_duplicates'}\n",
      "23:44:05 INFO - data factory dcdata_ is using local configuration without input/output path\n",
      "23:44:05 INFO - data factory dcdata_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory dcdata_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/03_exact_dedupe_out output_folder - output/04_fuzzy_dedupe_out/cleaned\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator fdclean started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of files is 6, source profile {'max_file_size': 0.011510848999023438, 'min_file_size': 0.003223419189453125, 'total_file_size': 0.050751686096191406}\n",
      "23:44:05 INFO - Completed 1 files (16.67%) in 0.0 min\n",
      "23:44:05 WARNING - table is empty, skipping processing\n",
      "23:44:05 INFO - Completed 2 files (33.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 3 files (50.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 4 files (66.67%) in 0.0 min\n",
      "23:44:05 INFO - Completed 5 files (83.33%) in 0.0 min\n",
      "23:44:05 INFO - Completed 6 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 6 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.0 min, execution result 0\n",
      "23:44:05 INFO - DataCleaning completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 311 ms, sys: 72.2 ms, total: 383 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_fdedup.transform_python import Fdedup\n",
    "\n",
    "STAGE = 4\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{output_exact_dedupe_dir}' --> output='{output_fuzzy_dedupe_dir}'\\n\", flush=True)\n",
    "\n",
    "result = Fdedup(input_folder=output_exact_dedupe_dir,\n",
    "                output_folder=output_fuzzy_dedupe_dir,\n",
    "                contents_column= \"contents\",\n",
    "                # document_id_column= \"doc_id\",\n",
    "                document_id_column= \"int_id_column\",\n",
    "                num_permutations= 112,\n",
    "                num_bands= 14,\n",
    "                num_minhashes_per_band= 8,\n",
    "                jaccard_similarity_threshold = 0.8, # between 0 - 1.  higher means more strict checking\n",
    "                operation_mode=\"filter_duplicates\",\n",
    "                # operation_mode=\"annotate\",\n",
    "                ).transform()\n",
    "# if result == 0:\n",
    "#     print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "# else:\n",
    "#     raise Exception (f\"❌ Stage:{STAGE}  failed (result={result})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c83592",
   "metadata": {},
   "source": [
    "### 7.2 - Inspect Output\n",
    "\n",
    "FuzzyDedupe will write documents that are filtered in **output/04_fuzzy_dedupe_out/cleaned** folder\n",
    "\n",
    "You will notice only one **earth.pdf** made it!  So fuzzy dedupe did filter out the almost identical doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "573faba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files before exact dedupe : 5\n",
      "Output files after exact dedupe : 4\n",
      "Near duplicate files removed :   1\n",
      "Displaying contents of :  output/04_fuzzy_dedupe_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>int_id_column</th>\n",
       "      <th>removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b</td>\n",
       "      <td>6571294142213095721</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-01-21T23:44:04.067075</td>\n",
       "      <td>0.636751</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>518a2e39-5c85-400f-8864-6bbc3ef20b1e</td>\n",
       "      <td>10026122586747302274</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-01-21T23:44:05.320766</td>\n",
       "      <td>0.619056</td>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>## Mars\\n\\n## Solar System\\n\\nOur solar system...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4</td>\n",
       "      <td>7758129997476962679</td>\n",
       "      <td>pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>717</td>\n",
       "      <td>2025-01-21T23:44:04.700038</td>\n",
       "      <td>0.629441</td>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>b895a249-e72d-4096-85fa-e0606d61aebf</td>\n",
       "      <td>14711865278795535908</td>\n",
       "      <td>pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>610</td>\n",
       "      <td>2025-01-21T23:44:01.917104</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                           contents  \\\n",
       "0  lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "1         spam.pdf                                           Free xxx   \n",
       "2         mars.pdf  ## Mars\\n\\n## Solar System\\n\\nOur solar system...   \n",
       "3   earth-copy.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0          1           0                 2   \n",
       "1          1           0                 2   \n",
       "2          1           0                11   \n",
       "3          1           0                11   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b   6571294142213095721  pdf   \n",
       "1  518a2e39-5c85-400f-8864-6bbc3ef20b1e  10026122586747302274  pdf   \n",
       "2  37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4   7758129997476962679  pdf   \n",
       "3  b895a249-e72d-4096-85fa-e0606d61aebf  14711865278795535908  pdf   \n",
       "\n",
       "                                                hash  size  \\\n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...    35   \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...     8   \n",
       "2  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...   717   \n",
       "3  6140cf695f269a3ddca6568536076756105ad3186086b2...   610   \n",
       "\n",
       "                date_acquired  pdf_convert_time  source_filename  \\\n",
       "0  2025-01-21T23:44:04.067075          0.636751  lorem-ipsum.pdf   \n",
       "1  2025-01-21T23:44:05.320766          0.619056         spam.pdf   \n",
       "2  2025-01-21T23:44:04.700038          0.629441         mars.pdf   \n",
       "3  2025-01-21T23:44:01.917104          0.993879   earth-copy.pdf   \n",
       "\n",
       "                                            doc_hash  int_id_column removed  \n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...              3      []  \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...              5      []  \n",
       "2  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...              4      []  \n",
       "3  6140cf695f269a3ddca6568536076756105ad3186086b2...              0      []  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = read_parquet_files_as_df(output_exact_dedupe_dir)\n",
    "output_df = read_parquet_files_as_df(os.path.join(output_fuzzy_dedupe_dir, \"cleaned\"))\n",
    "\n",
    "# print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "# print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "print (f\"Input files before exact dedupe : {input_df.shape[0]:,}\")\n",
    "print (f\"Output files after exact dedupe : {output_df.shape[0]:,}\")\n",
    "print (\"Near duplicate files removed :  \", (input_df.shape[0] - output_df.shape[0]))\n",
    "\n",
    "print (\"Displaying contents of : \", output_fuzzy_dedupe_dir)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0598a0",
   "metadata": {},
   "source": [
    "## Step-8: Document Quality\n",
    "\n",
    "This handy plugin will score documents across many metrics.\n",
    "\n",
    "Here we will look for 'bad words' metric.\n",
    "\n",
    "[Document quality documentation](https://github.com/IBM/data-prep-kit/tree/dev/transforms/language/doc_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949c2c4",
   "metadata": {},
   "source": [
    "### 8.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b485f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃🏼 STAGE-5: Processing input='output/04_fuzzy_dedupe_out/cleaned' --> output='output/05_doc_quality_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:44:05 INFO - doc_quality parameters are : {'text_lang': 'en', 'doc_content_column': 'contents', 'bad_word_filepath': '/home/sujee/apps/anaconda3/envs/dpk-2-pdf-processing/lib/python3.11/site-packages/dpk_doc_quality/ldnoobw/en', 's3_cred': None, 'docq_data_factory': <data_processing.data_access.data_access_factory.DataAccessFactory object at 0x775575dad410>}\n",
      "23:44:05 INFO - data factory docq_ is using local configuration without input/output path\n",
      "23:44:05 INFO - data factory docq_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory docq_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - pipeline id pipeline_id\n",
      "23:44:05 INFO - code location None\n",
      "23:44:05 INFO - data factory data_ is using local data access: input_folder - output/04_fuzzy_dedupe_out/cleaned output_folder - output/05_doc_quality_out\n",
      "23:44:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:44:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:44:05 INFO - orchestrator docq started at 2025-01-21 23:44:05\n",
      "23:44:05 INFO - Number of files is 5, source profile {'max_file_size': 0.011510848999023438, 'min_file_size': 0.0035142898559570312, 'total_file_size': 0.040172576904296875}\n",
      "23:44:05 INFO - Load badwords found locally from /home/sujee/apps/anaconda3/envs/dpk-2-pdf-processing/lib/python3.11/site-packages/dpk_doc_quality/ldnoobw/en\n",
      "23:44:05 INFO - Completed 1 files (20.0%) in 0.0 min\n",
      "23:44:05 WARNING - table is empty, skipping processing\n",
      "23:44:05 INFO - Completed 2 files (40.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 3 files (60.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 4 files (80.0%) in 0.0 min\n",
      "23:44:05 INFO - Completed 5 files (100.0%) in 0.0 min\n",
      "23:44:05 INFO - Done processing 5 files, waiting for flush() completion.\n",
      "23:44:05 INFO - done flushing in 0.0 sec\n",
      "23:44:05 INFO - Completed execution in 0.0 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stage:5 completed successfully\n",
      "CPU times: user 31.5 ms, sys: 2.81 ms, total: 34.3 ms\n",
      "Wall time: 28.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_doc_quality.transform_python import DocQuality\n",
    "\n",
    "STAGE = 5\n",
    "output_fuzzy_dedupe_cleaned_dir = os.path.join(output_fuzzy_dedupe_dir, \"cleaned\")\n",
    "print (f\"🏃🏼 STAGE-{STAGE}: Processing input='{output_fuzzy_dedupe_cleaned_dir}' --> output='{output_doc_quality_dir}'\\n\", flush=True)\n",
    "\n",
    "result = DocQuality(input_folder=output_fuzzy_dedupe_cleaned_dir,\n",
    "                    output_folder= output_doc_quality_dir,\n",
    "                    docq_text_lang = \"en\",\n",
    "                    docq_doc_content_column =\"contents\",\n",
    "                    ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"✅ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"❌ Stage:{STAGE}  failed (result={result})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccefd3e",
   "metadata": {},
   "source": [
    "### 8.2 - Inspect the Output\n",
    "\n",
    "We will see several new columns starting with the name **docq_**.\n",
    "\n",
    "We will look at a metric **docq_contain_bad_word** and filter out any documents that have bad words.\n",
    "\n",
    "For more information see : [Doc Quality documentation](https://github.com/IBM/data-prep-kit/tree/dev/transforms/language/doc_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3225f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying contents of :  output/05_doc_quality_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_mean_word_len</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b</td>\n",
       "      <td>6571294142213095721</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>518a2e39-5c85-400f-8864-6bbc3ef20b1e</td>\n",
       "      <td>10026122586747302274</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>## Mars\\n\\n## Solar System\\n\\nOur solar system...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4</td>\n",
       "      <td>7758129997476962679</td>\n",
       "      <td>pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>4.688000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>b895a249-e72d-4096-85fa-e0606d61aebf</td>\n",
       "      <td>14711865278795535908</td>\n",
       "      <td>pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>610</td>\n",
       "      <td>...</td>\n",
       "      <td>4.541284</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                           contents  \\\n",
       "0  lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "1         spam.pdf                                           Free xxx   \n",
       "2         mars.pdf  ## Mars\\n\\n## Solar System\\n\\nOur solar system...   \n",
       "3   earth-copy.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0          1           0                 2   \n",
       "1          1           0                 2   \n",
       "2          1           0                11   \n",
       "3          1           0                11   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  ee1fe28d-fb19-4456-83ac-42a9c7ed2c7b   6571294142213095721  pdf   \n",
       "1  518a2e39-5c85-400f-8864-6bbc3ef20b1e  10026122586747302274  pdf   \n",
       "2  37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4   7758129997476962679  pdf   \n",
       "3  b895a249-e72d-4096-85fa-e0606d61aebf  14711865278795535908  pdf   \n",
       "\n",
       "                                                hash  size  ...  \\\n",
       "0  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...    35  ...   \n",
       "1  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...     8  ...   \n",
       "2  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...   717  ...   \n",
       "3  6140cf695f269a3ddca6568536076756105ad3186086b2...   610  ...   \n",
       "\n",
       "  docq_mean_word_len  docq_symbol_to_word_ratio docq_sentence_count  \\\n",
       "0           5.000000                   0.000000                   1   \n",
       "1           3.500000                   0.000000                   1   \n",
       "2           4.688000                   0.032000                   8   \n",
       "3           4.541284                   0.027523                   9   \n",
       "\n",
       "  docq_lorem_ipsum_ratio  docq_curly_bracket_ratio docq_contain_bad_word  \\\n",
       "0               0.085714                       0.0                 False   \n",
       "1               0.000000                       0.0                  True   \n",
       "2               0.000000                       0.0                 False   \n",
       "3               0.000000                       0.0                 False   \n",
       "\n",
       "   docq_bullet_point_ratio  docq_ellipsis_line_ratio  \\\n",
       "0                 0.000000                       0.0   \n",
       "1                 0.000000                       0.0   \n",
       "2                 0.176471                       0.0   \n",
       "3                 0.176471                       0.0   \n",
       "\n",
       "   docq_alphabet_word_ratio  docq_contain_common_en_words  \n",
       "0                  1.000000                         False  \n",
       "1                  1.000000                         False  \n",
       "2                  0.880000                          True  \n",
       "3                  0.880734                          True  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = read_parquet_files_as_df(output_doc_quality_dir)\n",
    "print (\"Displaying contents of : \", output_doc_quality_dir)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa3bd2",
   "metadata": {},
   "source": [
    "### 8.3 - Filtering 'quality' documents\n",
    "\n",
    "So from the output above we see **spam.pdf** is flagged for containing bad words (see column **docq_contain_bad_word**).\n",
    "\n",
    "Also **lorem.pdf** is flagged for place holder content **lorem ipsum**\n",
    "\n",
    "We are going to filter them both out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dac1c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_mean_word_len</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mars.pdf</td>\n",
       "      <td>## Mars\\n\\n## Solar System\\n\\nOur solar system...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4</td>\n",
       "      <td>7758129997476962679</td>\n",
       "      <td>pdf</td>\n",
       "      <td>a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>4.688000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earth-copy.pdf</td>\n",
       "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>b895a249-e72d-4096-85fa-e0606d61aebf</td>\n",
       "      <td>14711865278795535908</td>\n",
       "      <td>pdf</td>\n",
       "      <td>6140cf695f269a3ddca6568536076756105ad3186086b2...</td>\n",
       "      <td>610</td>\n",
       "      <td>...</td>\n",
       "      <td>4.541284</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                           contents  \\\n",
       "2        mars.pdf  ## Mars\\n\\n## Solar System\\n\\nOur solar system...   \n",
       "3  earth-copy.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "2          1           0                11   \n",
       "3          1           0                11   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "2  37f9901a-f0b3-49c5-b5cd-dbfeb0126cd4   7758129997476962679  pdf   \n",
       "3  b895a249-e72d-4096-85fa-e0606d61aebf  14711865278795535908  pdf   \n",
       "\n",
       "                                                hash  size  ...  \\\n",
       "2  a3a4bb3b8f4f441d6d669e09f0cd07a9420d06850cf63e...   717  ...   \n",
       "3  6140cf695f269a3ddca6568536076756105ad3186086b2...   610  ...   \n",
       "\n",
       "  docq_mean_word_len  docq_symbol_to_word_ratio docq_sentence_count  \\\n",
       "2           4.688000                   0.032000                   8   \n",
       "3           4.541284                   0.027523                   9   \n",
       "\n",
       "  docq_lorem_ipsum_ratio  docq_curly_bracket_ratio docq_contain_bad_word  \\\n",
       "2                    0.0                       0.0                 False   \n",
       "3                    0.0                       0.0                 False   \n",
       "\n",
       "   docq_bullet_point_ratio  docq_ellipsis_line_ratio  \\\n",
       "2                 0.176471                       0.0   \n",
       "3                 0.176471                       0.0   \n",
       "\n",
       "   docq_alphabet_word_ratio  docq_contain_common_en_words  \n",
       "2                  0.880000                          True  \n",
       "3                  0.880734                          True  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs_df = read_parquet_files_as_df(output_doc_quality_dir)\n",
    "\n",
    "# remove documents with badwords\n",
    "clean_docs_df = all_docs_df[all_docs_df['docq_contain_bad_word'] == False]\n",
    "\n",
    "# also filter out 'lorem ipsum' text\n",
    "clean_docs_df = clean_docs_df[clean_docs_df['docq_lorem_ipsum_ratio'] == 0]\n",
    "\n",
    "clean_docs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e12630-be6b-4188-a925-77117155617b",
   "metadata": {
    "id": "f5e12630-be6b-4188-a925-77117155617b"
   },
   "source": [
    "## Step-9: Copy output to final output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16dee3b8-31dc-4168-8adb-f2a0a0b5e207",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16dee3b8-31dc-4168-8adb-f2a0a0b5e207",
    "outputId": "31f09b58-7b2d-48bb-9dac-bc0ba9625c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved parquet output to 'output/output_final/pq'\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(output_final_dir, ignore_errors=True)\n",
    "shutil.os.makedirs(output_final_dir, exist_ok=True)\n",
    "\n",
    "output_final_dir_parquet = os.path.join (output_final_dir, 'pq')\n",
    "shutil.os.makedirs(output_final_dir_parquet, exist_ok=True)\n",
    "\n",
    "output_final_dir_markdown = os.path.join (output_final_dir, 'markdown')\n",
    "shutil.os.makedirs(output_final_dir_markdown, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06ce4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CLEAN parquet output to 'output/output_final/pq'\n"
     ]
    }
   ],
   "source": [
    "## save parquet\n",
    "\n",
    "clean_docs_df.to_parquet(os.path.join(output_final_dir_parquet, \"clean_docs.parquet\"))\n",
    "print (f\"✅ Saved CLEAN parquet output to '{output_final_dir_parquet}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e175302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CLEAN markdown output to 'output/output_final/markdown'\n"
     ]
    }
   ],
   "source": [
    "## save markdown text\n",
    "\n",
    "for index, row in clean_docs_df.iterrows():\n",
    "    output_file_name = os.path.join (output_final_dir_markdown, row['filename'] + '.md')\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "        output_file.write(row['contents'])\n",
    "        \n",
    "print (f\"✅ Saved CLEAN markdown output to '{output_final_dir_markdown}'\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dpk-2-pdf-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06f9b33494984e4885d5aad813d1d2bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cb3bbf7d724411cbe9831543a4aecc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553f3c16839a49d79591d0fc4862bed6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7053c9606a414e978636a7e241909504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cb3bbf7d724411cbe9831543a4aecc0",
      "placeholder": "​",
      "style": "IPY_MODEL_06f9b33494984e4885d5aad813d1d2bc",
      "value": " 10/10 [00:00&lt;00:00, 349.38it/s]"
     }
    },
    "724778729161445c98b187031ae4f67c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97b603697cfa4b4ea4e6735b6768ca35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e87e8d3262c54cfaaa8768505edacda3",
       "IPY_MODEL_b78aa40816e44f7fbebcb24ca68818b3",
       "IPY_MODEL_7053c9606a414e978636a7e241909504"
      ],
      "layout": "IPY_MODEL_da0787b239764847a731083997780a85"
     }
    },
    "9d184ed175f0403fb03c2e13dfd04e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b78aa40816e44f7fbebcb24ca68818b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d184ed175f0403fb03c2e13dfd04e0a",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_724778729161445c98b187031ae4f67c",
      "value": 10
     }
    },
    "c0eb5bc8f6ee427ca42204b3c56f9a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da0787b239764847a731083997780a85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e87e8d3262c54cfaaa8768505edacda3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_553f3c16839a49d79591d0fc4862bed6",
      "placeholder": "​",
      "style": "IPY_MODEL_c0eb5bc8f6ee427ca42204b3c56f9a4e",
      "value": "Fetching 10 files: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
