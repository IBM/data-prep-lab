{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd55886-5f5b-4794-838e-ef8179fb0394",
   "metadata": {},
   "source": [
    "##### **** These pip installs need to be adapted to use the appropriate release level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c45c3c6-e4d7-4e61-8de6-32d61f2ce695",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install 'data-prep-toolkit-transforms[lang_id]==1.0.0a0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407fd4e4-265d-4ec7-bbc9-b43158f5f1f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **** Configure the transform parameters. The set of dictionary keys holding DocIDTransform configuration for values are as follows: \n",
    "| Key name  | Default  | Description |\n",
    "|------------|----------|--------------|\n",
    "| _model_credential_ | _unset_ | specifies the credential you use to get model. This will be huggingface token. [Guide to get huggingface token](https://huggingface.co/docs/hub/security-tokens) |\n",
    "| _model_kind_ | _unset_ | specifies what kind of model you want to use for language identification. Currently, only `fasttext` is available. |\n",
    "| _model_url_ | _unset_ |  specifies url that model locates. For fasttext, this will be repo nme of the model, like `facebook/fasttext-language-identification` |\n",
    "| _content_column_name_ | `contents` | specifies name of the column containing documents |\n",
    "| _output_lang_column_name_ | `lang` | specifies name of the output column to hold predicted language code |\n",
    "| _output_score_column_name_ | `score` | specifies name of the output column to hold score of prediction |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1f782-0e61-485c-8670-81066beb734c",
   "metadata": {},
   "source": [
    "##### ***** Import required classes and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9669273a-8fcc-4b40-9b20-8df658e2ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpk_lang_id.transform_python import LangId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234563c-2924-4150-8a31-4aec98c1bf33",
   "metadata": {},
   "source": [
    "##### ***** Setup runtime parameters for this transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "badafb96-64d2-4bb8-9f3e-b23713fd5c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:46:10 INFO - lang_id parameters are : {'model_credential': 'PUT YOUR OWN HUGGINGFACE CREDENTIAL', 'model_kind': 'fasttext', 'model_url': 'facebook/fasttext-language-identification', 'content_column_name': 'contents', 'output_lang_column_name': 'lang', 'output_score_column_name': 'score'}\n",
      "21:46:10 INFO - pipeline id pipeline_id\n",
      "21:46:10 INFO - code location None\n",
      "21:46:10 INFO - data factory data_ is using local data access: input_folder - dedup-files output_folder - langId-files\n",
      "21:46:10 INFO - data factory data_ max_files -1, n_sample -1\n",
      "21:46:10 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "21:46:10 INFO - orchestrator lang_id started at 2024-12-13 21:46:10\n",
      "21:46:10 INFO - Number of files is 1, source profile {'max_file_size': 0.031200408935546875, 'min_file_size': 0.031200408935546875, 'total_file_size': 0.031200408935546875}\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "21:46:12 INFO - Completed 1 files (100.0%) in 0.001 min\n",
      "21:46:12 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "21:46:12 INFO - done flushing in 0.0 sec\n",
      "21:46:12 INFO - Completed execution in 0.03 min, execution result 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LangId(input_folder= \"dedup-files\",\n",
    "        output_folder= \"langId-files\",\n",
    "        lang_id_model_credential= \"PUT YOUR OWN HUGGINGFACE CREDENTIAL\",\n",
    "        lang_id_model_kind= \"fasttext\",\n",
    "        lang_id_model_url= \"facebook/fasttext-language-identification\",\n",
    "        lang_id_content_column_name= \"contents\").transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df5adf-4717-4a03-864d-9151cd3f134b",
   "metadata": {},
   "source": [
    "##### **** The specified folder will include the transformed parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7276fe84-6512-4605-ab65-747351e13a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>lang</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;!-- image --&gt;</td>\n",
       "      <td>vi</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>## Docling Technical Report\\n\\nVersion 1.0\\n\\n...</td>\n",
       "      <td>ko-Hang</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>## Abstract\\n\\nThis technical report introduce...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>## 1 Introduction\\n\\nConverting PDF documents ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>## 2 Getting Started\\n\\nTo use Docling, you ca...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>## 3 Processing pipeline\\n\\nDocling implements...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>## 3.1 PDF backends\\n\\nTwo basic requirements ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>## 3.2 AI models\\n\\nAs part of Docling, we ini...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>## Layout Analysis Model\\n\\nOur layout analysi...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>## Table Structure Recognition\\n\\nThe TableFor...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>## OCR\\n\\nDocling provides optional support fo...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>## 3.3 Assembly\\n\\nIn the ﬁnal pipeline stage,...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>## 3.4 Extensibility\\n\\nDocling provides a str...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>## 4 Performance\\n\\nIn this section, we establ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>## 5 Applications\\n\\nThanks to the high-qualit...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>## 6 Future work and contributions\\n\\nDocling ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>## References\\n\\n- [1] J. AI. Easyocr: Ready-t...</td>\n",
       "      <td>ko-Hang</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>## Appendix\\n\\nIn this section, we illustrate ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>## DocLayNet: A Large Human-Annotated Dataset ...</td>\n",
       "      <td>yue-Hant</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>## ABSTRACT\\n\\nAccuratedocumentlayoutanalysisi...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>## CCS CONCEPTS\\n\\n· Informationsystems → Docu...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>## DocLayNet: A Large Human-Annotated Dataset ...</td>\n",
       "      <td>ko-Hang</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>## ABSTRACT\\n\\nAccurate document layout analys...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>## CCS CONCEPTS\\n\\nÆ Information systems → Doc...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>## KEYWORDS\\n\\nPDF document conversion, layout...</td>\n",
       "      <td>ko-Hang</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>## ACM Reference Format:\\n\\nBirgit Pﬁtzmann, C...</td>\n",
       "      <td>yue-Hant</td>\n",
       "      <td>0.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>## ACMReferenceFormat:\\n\\nBirgitP/f\\_itzmann,C...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>## 5 EXPERIMENTS\\n\\nTheprimarygoalofDocLayNeti...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>## Baselines for Object Detection\\n\\nInTable2,...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>## 5 EXPERIMENTS\\n\\nIne crimary goal DochayNor...</td>\n",
       "      <td>ko-Hang</td>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>## Baselines for Object Detection\\n\\nptesenl b...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             contents      lang  score\n",
       "0                                      <!-- image -->        vi  0.624\n",
       "1   ## Docling Technical Report\\n\\nVersion 1.0\\n\\n...   ko-Hang  0.215\n",
       "2   ## Abstract\\n\\nThis technical report introduce...        en  0.988\n",
       "3   ## 1 Introduction\\n\\nConverting PDF documents ...        en  0.997\n",
       "4   ## 2 Getting Started\\n\\nTo use Docling, you ca...        en  0.985\n",
       "5   ## 3 Processing pipeline\\n\\nDocling implements...        en  0.999\n",
       "6   ## 3.1 PDF backends\\n\\nTwo basic requirements ...        en  0.975\n",
       "7   ## 3.2 AI models\\n\\nAs part of Docling, we ini...        en  0.999\n",
       "8   ## Layout Analysis Model\\n\\nOur layout analysi...        en  0.998\n",
       "9   ## Table Structure Recognition\\n\\nThe TableFor...        en  0.998\n",
       "10  ## OCR\\n\\nDocling provides optional support fo...        en  0.998\n",
       "11  ## 3.3 Assembly\\n\\nIn the ﬁnal pipeline stage,...        en  0.999\n",
       "12  ## 3.4 Extensibility\\n\\nDocling provides a str...        en  0.999\n",
       "13  ## 4 Performance\\n\\nIn this section, we establ...        en  0.992\n",
       "14  ## 5 Applications\\n\\nThanks to the high-qualit...        en  0.997\n",
       "15  ## 6 Future work and contributions\\n\\nDocling ...        en  0.999\n",
       "16  ## References\\n\\n- [1] J. AI. Easyocr: Ready-t...   ko-Hang  0.347\n",
       "17  ## Appendix\\n\\nIn this section, we illustrate ...        en  0.994\n",
       "18  ## DocLayNet: A Large Human-Annotated Dataset ...  yue-Hant  0.357\n",
       "19  ## ABSTRACT\\n\\nAccuratedocumentlayoutanalysisi...        en  0.982\n",
       "20  ## CCS CONCEPTS\\n\\n· Informationsystems → Docu...        en  0.729\n",
       "21  ## DocLayNet: A Large Human-Annotated Dataset ...   ko-Hang  0.267\n",
       "22  ## ABSTRACT\\n\\nAccurate document layout analys...        en  0.998\n",
       "23  ## CCS CONCEPTS\\n\\nÆ Information systems → Doc...        en  0.993\n",
       "24  ## KEYWORDS\\n\\nPDF document conversion, layout...   ko-Hang  0.488\n",
       "25  ## ACM Reference Format:\\n\\nBirgit Pﬁtzmann, C...  yue-Hant  0.369\n",
       "26  ## ACMReferenceFormat:\\n\\nBirgitP/f\\_itzmann,C...        en  0.929\n",
       "27  ## 5 EXPERIMENTS\\n\\nTheprimarygoalofDocLayNeti...        en  0.963\n",
       "28  ## Baselines for Object Detection\\n\\nInTable2,...        en  0.622\n",
       "29  ## 5 EXPERIMENTS\\n\\nIne crimary goal DochayNor...   ko-Hang  0.294\n",
       "30  ## Baselines for Object Detection\\n\\nptesenl b...        en  0.837"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "table = pq.read_table('langId-files/arxiv_org_2408.09869v5.pdf_application.parquet')\n",
    "table.to_pandas()[['contents','lang','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a75cf-f4a9-467d-87fa-ccbac1c9beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
